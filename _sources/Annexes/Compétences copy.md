
# Compétences abordées

## DigComp 2.2 Learning objectives

INFORMATION AND DATA LITERACY
1.1 BROWSING, SEARCHING AND FILTERING DATA, INFORMATION AND DIGITAL CONTENT

| Compétence  | Description     | Chapitres/Sections  |
| ---------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| 5 | Aware that AI algorithms work in ways that are usually not visible or easily understood by users. This is often referred to as “black box” decision-making as it may be impossible to trace back how and why an algorithm makes specific suggestions or predictions. | 3.2 |
|8 | Knows how to formulate search queries to achieve the desired output when interacting with conversational agents or smart speakers (e.g. Siri, Alexa, Cortana, Google Assistant), e.g. recognising that, for the system to be able to respond as required, the query must be unambiguous and spoken clearly so that the system can respond.| 2.1, 4.1, 4.2, 4.3 |
| 14 | Weighs the benefits and disadvantages of using AI-driven search engines (e.g. while they might help users find the desired information, they may compromise privacy and personal data, or subject the user to commercial interests).| 5.1, 5.2, 5.3, 5.4 |





1.2 EVALUATING DATA, INFORMATION AND DIGITAL CONTENT

20 - Knows that the term “deep-fakes” refers to AI-generated images, videos or audio recordings of events or persons that did not really happen (e.g. speeches by politicians, celebrity faces on pornographic imagery). They may be impossible to distinguish from the real thing.
21 - Aware that AI algorithms might not be configured to provide only the information that the user wants; they might also embody a commercial or political message (e.g. to encourage users to stay on the site, to watch or buy something particular, to share specific opinions). This can also have negative consequences (e.g. reproducing stereotypes, sharing misinformation).
22 - Aware that the data, on which AI depends, may include biases. If so, these biases can become automated and worsened by the use of AI. For example, search results about occupation may include stereotypes about male or female jobs (e.g. male bus drivers, female sales persons).


[UNESCO – AI Competency Framework for Students (2024)](https://unesdoc.unesco.org/ark:/48223/pf0000391105/PDF/391105eng.pdf.multi)

## AI competency framework for students


| Compétence  | Description     | Chapitres/Sections  |
| ---------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| CG4.1.1.1 | Foster an understanding that AI is human-led: Based on selected AI tools, explain to students that AI is human- led; facilitate students to develop a stepwise and integral comprehension of human agency which may cover principles on data ownership and data privacy, protection of human rights in collecting and processing data, explainability of AI methods, human control in deployment, and human determination in using AI for decision-making. Guide students to understand that AI cannot replace human thinking or intellectual development. | 1, 2, 5, 10 |



